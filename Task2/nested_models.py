import mathimport sklearnimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn.utils import shufflefrom abc import ABC, abstractmethodfrom numpy.random import default_rngfrom sklearn import metricsimport statsmodels.api as smimport scipy.stats as ssimport scipy.stats as statsfrom sklearn.linear_model import Lassofrom sklearn.linear_model import LinearRegressionfrom sklearn.preprocessing import StandardScalerfrom sklearn.model_selection import train_test_splitrng = default_rng(seed=0)# LINEAR REGRESSION FUNCTIONdef regression(Xtrain, Xtest, ytrain, ytest) :    reg = LinearRegression().fit(Xtrain, ytrain)        return reg.coef_, reg.intercept_, reg.score(Xtest, ytest)# DATA## We use auto-mpg dataset to work with### Loading datasetmpg = pd.read_csv('./auto-mpg.csv', na_values=['NA','?'])#checking for missing valuesmpg.isnull().values.any()#Checking number of NANs for each column, in order to understand how many missing values there are.print("# of NaN in each columns:", mpg.isnull().sum(), sep='\n')'''We can see that column "horsepower" has 6 missing values. We will fill those missing values with medians.'''### Pre Processing data, filling na valuescars = mpg['name']mpg.drop('name',1,inplace=True)med = mpg['horsepower'].median()mpg['horsepower'] = mpg['horsepower'].fillna(med) ### Selecting covariates columnscovariates = []for x in mpg.columns:    if x != 'mpg':        covariates.append(x)print(covariates)### Getting data for regression X = mpg[covariates].valuesy = mpg['mpg'].values###split data into testing and trainingX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)#Using Laso Regressionscaler = StandardScaler()Xs = Xfor i in range(X.shape[1]) :    Xs[:,i]= scaler.fit_transform(X[:,i].reshape(-1, 1))[:,0]def report_coef(names,coef,intercept):    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )    r = r.sort_values(by=['coef'])    display(r)    print("Intercept: {}".format(intercept))    plt.xlabel('covariate coefficient')    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))# Create linear regressionregressor = Lasso(random_state=0,alpha=0.1)# Fit/train LASSOregressor.fit(Xs,y)# Predictpred = regressor.predict(Xs)# Measure RMSE error.  RMSE is common for regression.score = np.sqrt(metrics.mean_squared_error(pred,y))print("Final score (RMSE): {}".format(score))names = list(mpg.columns.values)names.remove("mpg")report_coef(  names,  regressor.coef_,  regressor.intercept_)# Lasso with different alpha value# Create linear regressionregressor = Lasso(random_state=0,alpha=0.01)# Fit/train LASSOregressor.fit(Xs,y)# Predictpred = regressor.predict(Xs)# Measure RMSE error.  RMSE is common for regression.score = np.sqrt(metrics.mean_squared_error(pred,y))print("Final score (RMSE): {}".format(score))report_coef(  names,  regressor.coef_,  regressor.intercept_)# Create linear regressionregressor = Lasso(random_state=0,alpha=1)# Fit/train LASSOregressor.fit(Xs,y)# Predictpred = regressor.predict(Xs)# Measure RMSE error.  RMSE is common for regression.score = np.sqrt(metrics.mean_squared_error(pred,y))print("Final score (RMSE): {}".format(score))names = list(mpg.columns.values)names.remove("mpg")report_coef(  names,  regressor.coef_,  regressor.intercept_)#Comparison using model  ùëÖ2  score and RMSEa,b,c = regression(X_train, X_test, y_train, y_test)print('a :', a)print('b :', b)print('Regression R2 score :', c)# build the modelmodel = LinearRegression()model.fit(X_train, y_train)#calculate the predictions of the linear regression modely_pred = model.predict(X_test)# Mean and RMSEprint('Covariates Used :', covariates)print('Mean:', np.mean(y_test))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))print('R2 Score : ', model.score(X_test, y_test))X_del = np.delete(X, 1,1)print(X.shape)print(X_del.shape)n = len(covariates)for i in range(n):    # Dropping covariates[i]    new_covariates = [covariates[j] for j in range(n) if j != i]    # New covariates Input    new_X = np.delete(X, i, 1)    new_X_train = np.delete(X_train, i, 1)    new_X_test = np.delete(X_test, i, 1)    # build model    model = LinearRegression()    model.fit(new_X_train, y_train)    # calculate the predictions of the linear regression model    new_y_pred = model.predict(new_X_test)    # Mean and RMSE    print('Covariates Dropped :', covariates[i])    print('Mean:', np.mean(y_test))    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, new_y_pred)))    print('R2 Score : ', model.score(new_X_test, y_test))    print('---------------------------------------------')#Using Only weights# New covariates Inputnew_X = X[:,3]new_X_train = X_train[:,3]new_X_test = X_test[:,3]#build modelmodel = LinearRegression()model.fit(new_X_train.reshape(-1,1), y_train)#calculate the predictions of the linear regression modelnew_y_pred = model.predict(new_X_test.reshape(-1,1))print('Covariates Used :', covariates[3])print('Mean:', np.mean(y_test))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, new_y_pred)))print('R2 Score : ', model.score(new_X_test.reshape(-1,1), y_test))#Using Only years# New covariates Inputnew_X = X[:,5]new_X_train = X_train[:,5]new_X_test = X_test[:,5]#build modelmodel = LinearRegression()model.fit(new_X_train.reshape(-1,1), y_train)#calculate the predictions of the linear regression modelnew_y_pred = model.predict(new_X_test.reshape(-1,1))print('Covariates Used :', covariates[5])print('Mean:', np.mean(y_test))print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, new_y_pred)))print('R2 Score : ', model.score(new_X_test.reshape(-1,1), y_test))#Using Only wights and years# New covariates Inputnew_X = X[:,[3,5]]new_X_train = X_train[:,[3,5]]new_X_test = X_test[:,[3,5]]#build modelmodel = LinearRegression()model.fit(new_X_train, y_train)#calculate the predictions of the linear regression modelnew_y_pred = model.predict(new_X_test)print('Covariates Used :', [covariates[i] for i in [3,5]])print('Mean:', np.mean(y_test))print('Root Mean Squared Error Full Model: 3.409213715841733')print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, new_y_pred)))print('R2 Score Full Model : 0.8139447246621095 ')print('R2 Score : ', model.score(new_X_test, y_test))# New covariates Inputnew_X = X[:,[3,5,6]]new_X_train = X_train[:,[3,5,6]]new_X_test = X_test[:,[3,5,6]]#build modelmodel = LinearRegression()model.fit(new_X_train, y_train)#calculate the predictions of the linear regression modelnew_y_pred = model.predict(new_X_test)print('Covariates Used :', [covariates[i] for i in [3,5,6]])print('Mean:', np.mean(y_test))print('Root Mean Squared Error Full Model: 3.409213715841733')print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, new_y_pred)))print('R2 Score Full Model : 0.8139447246621095 ')print('R2 Score : ', model.score(new_X_test, y_test))#Comparison using model t-testn = len(covariates)for i in range(n):    # Dropping covariates[i]    new_covariates = [covariates[j] for j in range(n) if j != i]    # New covariates Input    new_X = np.delete(X, i, 1)    new_X_train = np.delete(X_train, i, 1)    new_X_test = np.delete(X_test, i, 1)    # build model    model = LinearRegression()    model.fit(new_X_train, y_train)    # calculate the predictions of the linear regression model    new_y_pred = model.predict(new_X_test)    # Making the t-test    tstat, pvalue = stats.ttest_ind(y_pred, new_y_pred, equal_var=False)    # Mean and RMSE    print('Covariates Dropped :', covariates[i])    print('t-test value:', tstat)    print('p-value:', pvalue)    if (pvalue < 0.95):        print(f'Including {covariates[i]} in the model is important')    else:        print(f' We fail to confirm the importance of including {covariates[i]}')    print('---------------------------------------------')#Comparison using model f-testy = mpg['mpg']exp_var = mpg[['cylinders', 'horsepower', 'year', 'weight', 'acceleration']]exp_var = sm.add_constant(exp_var)ols = sm.OLS(y, exp_var)ols_fit = ols.fit()ols_fit.summary()#Hypothesis 1A = np.array([[0,0,1,0,0,0],[0,0,0,1,0,0]])print(ols_fit.f_test(A))'''p Value is very small we reject null hypothesis'''#Hypothesis 2B = np.array([[0,1,0,0,0,0],[0,0,0,0,0,1]])print(ols_fit.f_test(B))'''p value is high we fail to reject'''