{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f49d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "from torchvision.datasets import MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d908c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with forward pass\n",
    "@np.vectorize\n",
    "def sigmoid (x):\n",
    "  return 1/(1+np.e**-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa5abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_sigmoid (x):\n",
    "  return x*(1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d63dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with forward pass\n",
    "@np.vectorize\n",
    "def relu (x):\n",
    "  return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b965e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_relu (x):\n",
    "  if x<0:\n",
    "    return 0\n",
    "  if x>0:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "989e12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  for i in len(X):\n",
    "    s = (np.e**-i)/(sum(np.e**-i))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87b18671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 no_of_hidden_layers,\n",
    "                 active_input_percentage,\n",
    "                 active_hidden_percentage):\n",
    "        \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes       \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.no_of_hidden_layers = no_of_hidden_layers          \n",
    "        self.active_input_percentage=active_input_percentage\n",
    "        self.active_hidden_percentage=active_input_percentage\n",
    "        self.create_weight_matrices()\n",
    "\n",
    "    def truncated_normal(mean, sd, low, upp):\n",
    "        return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "\n",
    "   #method to initialise the weight matrices of the NN     \n",
    "    def create_weight_matrices(self):  # add no_of_hidden_layers\n",
    "        \n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #shape parameters of wih\n",
    "        n = (self.no_of_in_nodes) * self.no_of_hidden_nodes\n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #random variates of weights connecting input and hidden nodes\n",
    "        self.wih = X.rvs(n).reshape((self.no_of_hidden_nodes, self.no_of_in_nodes ))\n",
    "\n",
    "        # if no_of_hidden_layers>1:\n",
    "        #   for i no_of_hidden_layers:\n",
    "        #     n = (self.no_of_hidden_nodes) * self.no_of_hidden_nodes\n",
    "        #     X = truncated_normal(mean, sd, low, upp)\n",
    "        #     self.whh = X.rvs(n).reshape((self.no_of_hidden_nodes,(self.no_of_hidden_nodes )))\n",
    "\n",
    "\n",
    "        #shape parameters of who\n",
    "        n = (self.no_of_hidden_nodes ) * self.no_of_out_nodes\n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #weights connecting hidden and output nodes\n",
    "        self.who = X.rvs(n).reshape((self.no_of_out_nodes,(self.no_of_hidden_nodes )))\n",
    "\n",
    "\n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\" \n",
    "        input_vector and target_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        #forward pass\n",
    "\n",
    "\n",
    "        #initialising with the mminimum dimension = 2\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        #multiplication of matrix wih with the input vector\n",
    "        output_vector1 = np.dot(self.wih, input_vector)\n",
    "        #calculated output passed to the activation function\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "\n",
    "        #multiplication of matrix who with the output vector\n",
    "        output_vector2 = np.dot(self.who, output_vector_hidden)\n",
    "        #calculated output passed to the activation function\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "\n",
    "        #derivative of the loss\n",
    "        output_errors = target_vector - output_vector_network\n",
    "        #derivative of the activation function\n",
    "        derivative_output = activation_derivative(output_vector_network)\n",
    "\n",
    "        # update the weights:\n",
    "        tmp = output_errors*derivative_output    \n",
    "        #multiply with the previous activation (output_vector_network)\n",
    "        who_update = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
    "        \n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, output_errors*derivative_output)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * activation_derivative(output_vector_hidden)\n",
    "        wih_update = self.learning_rate *np.dot(tmp, input_vector.T)\n",
    "        \n",
    "        \n",
    "        #update the weights \n",
    "        self.who += who_update\n",
    "        self.wih += wih_update\n",
    "            \n",
    "        \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              active_input_percentage=0.70,\n",
    "              active_hidden_percentage=0.70,\n",
    "              no_of_dropout_tests = 10):\n",
    "      \n",
    "      \n",
    "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"epoch: \", epochs)\n",
    "            for start in range(0, len(data_array), partition_length):\n",
    "                active_in_indices, active_hidden_indices = \\\n",
    "                           self.dropout_weight_matrices()\n",
    "                for i in range(start, start + partition_length):\n",
    "                    self.train_single(data_array[i][active_in_indices], \n",
    "                                     labels_one_hot_array[i]) \n",
    "                    \n",
    "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def dropout_weight_matrices(self):\n",
    "        # restore wih array, if it had been used for dropout\n",
    "        self.wih_orig = self.wih.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.who_orig = self.who.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.no_of_in_nodes * self.active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
    "                                      active_input_nodes))\n",
    "        active_hidden_nodes = int(self.no_of_hidden_nodes * self.active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
    "                                       active_hidden_nodes))\n",
    "        \n",
    "        self.wih = self.wih[:, active_input_indices][active_hidden_indices]       \n",
    "        self.who = self.who[:, active_hidden_indices]\n",
    "        \n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        return active_input_indices, active_hidden_indices\n",
    "    \n",
    "    def weight_matrices_reset(self, \n",
    "                              active_input_indices, \n",
    "                              active_hidden_indices):\n",
    "        \n",
    "        \"\"\"\n",
    "        self.wih and self.who contain the newly adapted values from the active nodes.\n",
    "        We have to reconstruct the original weight matrices by assigning the new values \n",
    "        from the active nodes\n",
    "        \"\"\"\n",
    " \n",
    "        temp = self.wih_orig.copy()[:,active_input_indices]\n",
    "        temp[active_hidden_indices] = self.wih\n",
    "        self.wih_orig[:, active_input_indices] = temp\n",
    "        self.wih = self.wih_orig.copy()\n",
    "        self.who_orig[:, active_hidden_indices] = self.who\n",
    "        self.who = self.who_orig.copy()\n",
    "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
    "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
    "        \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray   \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        #wih = self.wih * self.active_input_percentage\n",
    "        output_vector = np.dot(self.wih, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        output_vector = output_vector * (1-self.active_input_percentage)  #dropout %\n",
    "        return output_vector.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93afeff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
