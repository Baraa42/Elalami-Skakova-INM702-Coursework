{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bef51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec14319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\".\"\n",
    "\n",
    "filename = os.path.join(\"fashion-mnist_train.csv\")\n",
    "df = pd.read_csv(filename, na_values = [\"NA\", \"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6caf2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4488ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0        30        43   \n",
       "3           0  ...         3         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "59995       0  ...         0         0         0         0         0   \n",
       "59996       0  ...        73         0         0         0         0   \n",
       "59997       0  ...       160       162       163       135        94   \n",
       "59998       0  ...         0         0         0         0         0   \n",
       "59999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b484407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with forward pass\n",
    "@np.vectorize\n",
    "def sigmoid (x):\n",
    "  return 1/(1+np.e**-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b120b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_sigmoid (x):\n",
    "  return x*(1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "224aefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with forward pass\n",
    "@np.vectorize\n",
    "def relu (x):\n",
    "  return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f4b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_relu (x):\n",
    "  if x<0:\n",
    "    return 0\n",
    "  if x>0:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a604032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  for i in len(X):\n",
    "    s = (np.e**-i)/(sum(np.e**-i))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6852c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 no_of_hidden_layers,\n",
    "                 active_input_percentage,\n",
    "                 active_hidden_percentage):\n",
    "        \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes       \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.no_of_hidden_layers = no_of_hidden_layers          \n",
    "        self.active_input_percentage=active_input_percentage\n",
    "        self.active_hidden_percentage=active_input_percentage\n",
    "        self.create_weight_matrices()\n",
    "\n",
    "    def truncated_normal(mean, sd, low, upp):\n",
    "        return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "\n",
    "   #method to initialise the weight matrices of the NN     \n",
    "    def create_weight_matrices(self):  # add no_of_hidden_layers\n",
    "        \n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #shape parameters of wih\n",
    "        n = (self.no_of_in_nodes) * self.no_of_hidden_nodes\n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #random variates of weights connecting input and hidden nodes\n",
    "        self.wih = X.rvs(n).reshape((self.no_of_hidden_nodes, self.no_of_in_nodes ))\n",
    "\n",
    "        # if no_of_hidden_layers>1:\n",
    "        #   for i no_of_hidden_layers:\n",
    "        #     n = (self.no_of_hidden_nodes) * self.no_of_hidden_nodes\n",
    "        #     X = truncated_normal(mean, sd, low, upp)\n",
    "        #     self.whh = X.rvs(n).reshape((self.no_of_hidden_nodes,(self.no_of_hidden_nodes )))\n",
    "\n",
    "\n",
    "        #shape parameters of who\n",
    "        n = (self.no_of_hidden_nodes ) * self.no_of_out_nodes\n",
    "        X = truncated_normal(mean, sd, low, upp)\n",
    "        #weights connecting hidden and output nodes\n",
    "        self.who = X.rvs(n).reshape((self.no_of_out_nodes,(self.no_of_hidden_nodes )))\n",
    "\n",
    "\n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\" \n",
    "        input_vector and target_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        #forward pass\n",
    "\n",
    "\n",
    "        #initialising with the mminimum dimension = 2\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        #multiplication of matrix wih with the input vector\n",
    "        output_vector1 = np.dot(self.wih, input_vector)\n",
    "        #calculated output passed to the activation function\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "\n",
    "        #multiplication of matrix who with the output vector\n",
    "        output_vector2 = np.dot(self.who, output_vector_hidden)\n",
    "        #calculated output passed to the activation function\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "\n",
    "        #derivative of the loss\n",
    "        output_errors = target_vector - output_vector_network\n",
    "        #derivative of the activation function\n",
    "        derivative_output = activation_derivative(output_vector_network)\n",
    "\n",
    "        # update the weights:\n",
    "        tmp = output_errors*derivative_output    \n",
    "        #multiply with the previous activation (output_vector_network)\n",
    "        who_update = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
    "        \n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, output_errors*derivative_output)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * activation_derivative(output_vector_hidden)\n",
    "        wih_update = self.learning_rate *np.dot(tmp, input_vector.T)\n",
    "        \n",
    "        \n",
    "        #update the weights \n",
    "        self.who += who_update\n",
    "        self.wih += wih_update\n",
    "            \n",
    "        \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              epochs=1,\n",
    "              active_input_percentage=0.70,\n",
    "              active_hidden_percentage=0.70,\n",
    "              no_of_dropout_tests = 10):\n",
    "      \n",
    "      \n",
    "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"epoch: \", epochs)\n",
    "            for start in range(0, len(data_array), partition_length):\n",
    "                active_in_indices, active_hidden_indices = \\\n",
    "                           self.dropout_weight_matrices()\n",
    "                for i in range(start, start + partition_length):\n",
    "                    self.train_single(data_array[i][active_in_indices], \n",
    "                                     labels_one_hot_array[i]) \n",
    "                    \n",
    "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def dropout_weight_matrices(self):\n",
    "        # restore wih array, if it had been used for dropout\n",
    "        self.wih_orig = self.wih.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.who_orig = self.who.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.no_of_in_nodes * self.active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
    "                                      active_input_nodes))\n",
    "        active_hidden_nodes = int(self.no_of_hidden_nodes * self.active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
    "                                       active_hidden_nodes))\n",
    "        \n",
    "        self.wih = self.wih[:, active_input_indices][active_hidden_indices]       \n",
    "        self.who = self.who[:, active_hidden_indices]\n",
    "        \n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        return active_input_indices, active_hidden_indices\n",
    "    \n",
    "    def weight_matrices_reset(self, \n",
    "                              active_input_indices, \n",
    "                              active_hidden_indices):\n",
    "        \n",
    "        \"\"\"\n",
    "        self.wih and self.who contain the newly adapted values from the active nodes.\n",
    "        We have to reconstruct the original weight matrices by assigning the new values \n",
    "        from the active nodes\n",
    "        \"\"\"\n",
    " \n",
    "        temp = self.wih_orig.copy()[:,active_input_indices]\n",
    "        temp[active_hidden_indices] = self.wih\n",
    "        self.wih_orig[:, active_input_indices] = temp\n",
    "        self.wih = self.wih_orig.copy()\n",
    "        self.who_orig[:, active_hidden_indices] = self.who\n",
    "        self.who = self.who_orig.copy()\n",
    "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
    "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
    "        \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray   \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        #wih = self.wih * self.active_input_percentage\n",
    "        output_vector = np.dot(self.wih, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        output_vector = output_vector * (1-self.active_input_percentage)  #dropout %\n",
    "        return output_vector.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f00230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
