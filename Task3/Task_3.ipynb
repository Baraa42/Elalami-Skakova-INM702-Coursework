{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b782fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import truncnorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d69200",
   "metadata": {},
   "source": [
    "### put it in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c14274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with forward pass\n",
    "@np.vectorize\n",
    "def sigmoid (x):\n",
    "  return 1/(1+np.e**-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c95ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_sigmoid (x):\n",
    "  return x*(1.0-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c93aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with forward pass\n",
    "@np.vectorize\n",
    "def relu (x):\n",
    "  return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cbf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU activation function with backward pass\n",
    "@np.vectorize\n",
    "def d_relu (x):\n",
    "  if x<0:\n",
    "    return 0\n",
    "  if x>0:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cf9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    a = x - np.max(x, axis=0, keepdims=True)\n",
    "    new_a = np.exp(a)\n",
    "    result = new_a / np.new_a(new_a, axis=0, keepdims=True)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f340dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(target, output):\n",
    "    return -np.mean(target*np.log(output))\n",
    "\n",
    "def cross_entropy_matrix(output, target):\n",
    "    target = np.array(target)\n",
    "    output = np.array(output)\n",
    "    product = target*np.log(output)\n",
    "    errors = -np.sum(product, axis=1)\n",
    "    m = len(errors)\n",
    "    errors = np.sum(errors) / m\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e5a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal(mean = 0, sd =1, low = 0, upp = 0):\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59432bf0",
   "metadata": {},
   "source": [
    "### class NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4bc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, \n",
    "                 no_input_nodes, \n",
    "                 no_output_nodes, \n",
    "                 no_hidden_nodes, \n",
    "                 learning_rate, \n",
    "                 no_hidden_layers,\n",
    "                 activation_function, \n",
    "                 activation_derivative):\n",
    "        \n",
    "        self.no_input_nodes = no_input_nodes\n",
    "        self.no_output_nodes = no_output_nodes       \n",
    "        self.no_hidden_nodes = no_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.no_hidden_layers = no_hidden_layers          \n",
    "        self.activation_function = activation_function\n",
    "        self.activation_derivative = activation_derivative\n",
    "        self.weights()\n",
    "\n",
    "   #method to initialise the weight matrices of the NN     \n",
    "    def weights(self):\n",
    "        \n",
    "        weights =[]\n",
    "        tn = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        \n",
    "        #shape parameters of wih\n",
    "        n = self.no_input_nodes * self.no_hidden_nodes\n",
    "        #random variates of weights connecting input and hidden nodes\n",
    "        self.wih = tn.rvs(n).reshape(self.no_hidden_nodes, self.no_input_nodes )\n",
    "        weights.append(self.wih)\n",
    "        \n",
    "        if self.no_hidden_layers>=1:\n",
    "            for x in range(self.no_hidden_layers):\n",
    "                n = self.no_hidden_nodes * self.no_hidden_nodes\n",
    "                self.W = tn.rvs(n).reshape(self.no_hidden_nodes, self.no_hidden_nodes)\n",
    "                weights.append(self.W)\n",
    "\n",
    "        #shape parameters of who\n",
    "        n = self.no_hidden_nodes * self.no_output_nodes\n",
    "        #weights connecting hidden and output nodes\n",
    "        self.who = tn.rvs(n).reshape(self.no_output_nodes,self.no_hidden_nodes)\n",
    "        weights.append(self.who)\n",
    "        return weights\n",
    "    \n",
    "    def create_biases(self):    \n",
    "        bias = []\n",
    "        tn = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        if self.no_hidden_layers>=1:\n",
    "            for x in range(self.no_hidden_layers):\n",
    "                self.b = tn.rvs(self.no_hidden_nodes).reshape(-1,1)  \n",
    "                bias.append(self.b)\n",
    "        self.b = tn.rvs(self.no_output_nodes).reshape(-1,1) \n",
    "        bias.append(self.b)\n",
    "        return bias\n",
    "\n",
    "    def forward (self, X): \n",
    "        weights = self.weights()\n",
    "        bias = self.create_biases()\n",
    "        forward_l = []\n",
    "        Z=[]\n",
    "        A=[]\n",
    "        A.append(X)\n",
    "        a = X.T\n",
    "\n",
    "        for x in range(1, self.no_hidden_layers):\n",
    "            z = np.dot(weights[x], a) + bias[x]\n",
    "            a = self.activation_function(z)\n",
    "            Z.append(z)\n",
    "            A.append(a)\n",
    "        return Z, A, forward_l   # A3 z3 A2 Z2 A1 Z1\n",
    "  \n",
    "    \n",
    "    def backprop(self, X, target):\n",
    "        dZ=[]\n",
    "        dW = []\n",
    "        db=[]\n",
    "        forward = self.forward(X)\n",
    "        forward_A = forward[1]\n",
    "        forward_Z = forward[0]\n",
    "        weights = self.weights()\n",
    "        forward_a = sorted(forward_A, reverse = True) #A3, A2, A1\n",
    "        forward_z = sorted(forward_Z, reverse = True) #Z3, Z2, Z1\n",
    "        del forward_z[0] \n",
    "        new_a = forward_a[2:]\n",
    "        weights_l = sorted(weights, reverse = True) # W3, W2, W1\n",
    "        \n",
    "        \n",
    "        m = X.shape[0]\n",
    "        # deltas\n",
    "        #output\n",
    "        dZ3 = forward[-1] - target                            \n",
    "        dW3 = dZ3.dot(forward[-2].T)/m                        \n",
    "        db3 = np.sum(dZ3, axis=1, keepdims=True)/m \n",
    "        dZ.append(dZ3)\n",
    "        dW.append(dW3)\n",
    "        db.append(db3)\n",
    "        #hidden \n",
    "        \n",
    "        for x in range(new_a): \n",
    "            dZ = weights_l[x].T.dot(dZ3)*self.activation_derivative(forward_z[x])   \n",
    "            dW = dZ.dot(new_a[x].T)/m  \n",
    "            db = np.sum(dZ, axis=1, keepdims=True)/m  \n",
    "            dZ3 = dZ\n",
    "            dZ.append(dZ)\n",
    "            dW.append(dW)\n",
    "            db.append(db)\n",
    "            return dZ, dW, db\n",
    "        \n",
    "        #input\n",
    "        dZ1 = weights_A[1].T.dot(dZ[-1])*self.hidden_derivative_1(forward_Z[0])  \n",
    "        dW1 = dZ1.dot(X)/m                                     \n",
    "        db1 = np.sum(dZ1, axis=1, keepdims=True)/m  \n",
    "        dZ.append(dZ1)\n",
    "        dW.append(dW1)\n",
    "        db.append(db1)\n",
    "     \n",
    "        # Update\n",
    "        lr = self.learning_rate\n",
    "        W=[]\n",
    "        B=[]\n",
    "        for x in len (dZ):\n",
    "            w -=lr*dW[x]\n",
    "            b -=lr*db[x]\n",
    "            W.append(w)\n",
    "            B.append(b)\n",
    "            return W, B\n",
    "            \n",
    "    def predict(self, X_predict):\n",
    "        forward_list = self.forward(X_predict)\n",
    "        A_list = forward_list[1]\n",
    "        A = A_list[-1]\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def predict_class(self, X_predict):\n",
    "        A = self.predict(X_predict)\n",
    "        y_pred = np.argmax(A, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    def run(self, X_train, target, epochs=10):\n",
    "        costs = []\n",
    "        for i in range(epochs):\n",
    "            A = self.predict(X_train)\n",
    "            cost = cross_entropy(target, A)\n",
    "            costs.append(cost)\n",
    "            if i%100 == 0:\n",
    "                print(f'Loss after epoch {i} : {cost}')\n",
    "            self.backprop(X_train, target)\n",
    "        return costs  \n",
    "    \n",
    "    \n",
    "    def evaluate(self, X_evaluate, target):\n",
    "        '''\n",
    "        return accuracy score, target must be the classes and not the hot encoded target\n",
    "        '''\n",
    "        \n",
    "        y_pred = self.predict_class(X_evaluate)\n",
    "        accuracy = classification_rate(y_pred, target)\n",
    "        print('Accuracy :', accuracy)\n",
    "        return accuracy\n",
    "          \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1885541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train.reshape(60000,784)\n",
    "X_test.reshape(10000,784)\n",
    "\n",
    "X_train = X_train / 255 \n",
    "X_test = X_test / 255 \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10).T\n",
    "y_test = to_categorical(y_test, 10).T\n",
    "\n",
    "\n",
    "D = X_train.shape[1]\n",
    "K = y_train.shape[0]\n",
    "M=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61d478",
   "metadata": {},
   "source": [
    "the value of each pixel in the image is in the interval [0.255]. \n",
    "implementing a normalization function, and then apply it to each image in the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66036019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = x_train / 255 \n",
    "# X_test = x_test / 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294d749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 28 #width and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e16445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_pixels = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf163259",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(no_input_nodes =D, \n",
    "                 no_output_nodes= K, \n",
    "                 no_hidden_nodes = D+1, \n",
    "                 learning_rate = 0.01, \n",
    "                 no_hidden_layers = 1,  \n",
    "                 activation_function = relu, \n",
    "                 activation_derivative = d_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053c48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp/ipykernel_11208/1804537686.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(target*np.log(output))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,60000) (60000,28,28) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11208/2376200078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11208/1709327262.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, X_train, target, epochs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0mcosts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11208/1804537686.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(target, output)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_entropy_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,60000) (60000,28,28) "
     ]
    }
   ],
   "source": [
    "c = nn.run(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbc45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4c63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0029e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe5767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2225c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
